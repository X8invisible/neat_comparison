
@book{marsland_machine_2015,
	location = {Boca Raton},
	edition = {2nd ed.},
	title = {Machine learning : an algorithmic perspective},
	abstract = {Introduction. Linear Discriminants. The Multi-Layer Perceptron. Radial Basis Functions and Splines. Support Vector Machines. Learning with Trees. Decision by Committee: Ensemble Learning. Probability and Learning. Unsupervised Learning. Dimensionality Reduction. Optimization and Search. Evolutionary Learning. Reinforcement Learning. Markov Chain Monte Carlo ({MCMC}) Methods. Graphical Models. Python.},
	publisher = {Boca Raton : {CRC} Press},
	author = {Marsland, Stephen},
	year = {2015},
	keywords = {Algorithms., Electronic books, Machine learning.}
}

@online{sharma_understanding_2017,
	title = {Understanding Activation Functions in Neural Networks},
	url = {https://link.medium.com/1H2Vt6LQoZ},
	titleaddon = {Medium},
	author = {Sharma, Avinash},
	urlyear = {2019-10-21},
	year = {2017},
	langid = {english},
	file = {Snapshot:C\:\\Users\\Andrei\\Zotero\\storage\\QWVIJR9I\\understanding-activation-functions-in-neural-networks-9491262884e0.html:text/html}
}

@book{thrun_learning_2012,
	title = {Learning to Learn},
	isbn = {978-1-4615-5529-2},
	pagetotal = {346},
	publisher = {Springer Science \& Business Media},
	author = {Thrun, Sebastian and Pratt, Lorien},
	year = {2012},
	langid = {english},
	note = {Google-Books-{ID}: X\_jpBwAAQBAJ},
	keywords = {Computers / Information Technology, Computers / Intelligence ({AI}) \& Semantics}
}

@book{agoston_e._eiben_introduction_2015,
	location = {Berlin},
	edition = {Second edition.},
	title = {Introduction to evolutionary computing},
	isbn = {978-3-662-44874-8},
	series = {Natural computing series},
	publisher = {Springer},
	author = {{Agoston E. Eiben}},
	editora = {{J. E Smith (James E. ) author}},
	editoratype = {collaborator},
	year = {2015}
}

@book{nikhil_ketkar_deep_2017,
	location = {United States},
	title = {Deep learning with Python: A hands-on introduction},
	isbn = {978-1-4842-2766-4},
	shorttitle = {Deep learning with Python},
	publisher = {Apress},
	author = {{Nikhil Ketkar}},
	year = {2017},
	keywords = {{COMPUTERS}, Programming Languages}
}

@online{chris_nicholson_beginners_2019,
	title = {A Beginner's Guide to Backpropagation in Neural Networks},
	url = {http://skymind.ai/wiki/backpropagation},
	abstract = {A beginner's reference to Backpropagation, a key algorithm in training neural networks.},
	titleaddon = {Skymind},
	author = {{Chris Nicholson}},
	urlyear = {2019-11-02},
	year = {2019},
	langid = {english},
	file = {Snapshot:C\:\\Users\\Andrei\\Zotero\\storage\\MB5R6X9R\\backpropagation.html:text/html}
}

@book{rob_j_hyndman_forecasting:_2018,
	edition = {2nd edition},
	title = {Forecasting: Principles and Practice},
	url = {https://Otexts.com/fpp2/},
	shorttitle = {Forecasting},
	author = {{Rob J Hyndman} and Athanasopoulos, George},
	urlyear = {2019-11-04},
	year = {2018},
	file = {Snapshot:C\:\\Users\\Andrei\\Zotero\\storage\\FNJ7DUZD\\fpp2.html:text/html}
}

@book{gurney_introduction_1997,
	location = {Bristol, {PA}, {USA}},
	title = {An Introduction to Neural Networks},
	isbn = {978-1-85728-673-1},
	abstract = {From the Publisher:An Introduction to Nueral Networks will be warmly welcomed by a wide readership seeking an authoritative treatment of this key subject without an intimidating level of mathematics in the presentation.},
	publisher = {Taylor \& Francis, Inc.},
	author = {Gurney, Kevin},
	year = {1997}
}

@article{wang_three_2007,
	title = {Three fundamental misconceptions of Artificial Intelligence},
	volume = {19},
	issn = {0952-813X},
	url = {https://doi.org/10.1080/09528130601143109},
	doi = {10.1080/09528130601143109},
	pages = {249--268},
	number = {3},
	journaltitle = {Journal of Experimental \& Theoretical Artificial Intelligence},
	author = {Wang, Pei},
	urlyear = {2019-11-04},
	year = {2007},
	keywords = {Algorithmization, Axiomatization, Empirical reasoning, Formalization, Limitation of {AI}},
	file = {Snapshot:C\:\\Users\\Andrei\\Zotero\\storage\\VGC6SSBC\\09528130601143109.html:text/html}
}

@article{mcculloch_logical_1943,
	title = {A logical calculus of the ideas immanent in nervous activity},
	volume = {5},
	issn = {1522-9602},
	url = {https://doi.org/10.1007/BF02478259},
	doi = {10.1007/BF02478259},
	abstract = {Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
	pages = {115--133},
	number = {4},
	journaltitle = {The bulletin of mathematical biophysics},
	shortjournal = {Bulletin of Mathematical Biophysics},
	author = {{McCulloch}, Warren S. and Pitts, Walter},
	urlyear = {2019-11-04},
	year = {1943},
	langid = {english},
	keywords = {Excitatory Synapse, Inhibitory Synapse, Nervous Activity, Spatial Summation, Temporal Summation}
}

@article{rosenblatt_perceptron:_1958,
	title = {The perceptron: a probabilistic model for information storage and organization in the brain.},
	volume = {65},
	pages = {386},
	number = {6},
	journaltitle = {Psychological review},
	author = {Rosenblatt, Frank},
	year = {1958}
}

@inproceedings{mitchell_explanation-based_1993,
	title = {Explanation-based neural network learning for robot control},
	pages = {287--294},
	booktitle = {Advances in neural information processing systems},
	author = {Mitchell, Tom M and Thrun, Sebastian B},
	year = {1993}
}

@article{goldberg_genetic_1988,
	title = {Genetic algorithms and machine learning},
	volume = {3},
	pages = {95--99},
	number = {2},
	journaltitle = {Machine learning},
	author = {Goldberg, David E and Holland, John H},
	year = {1988}
}

@book{nielsen_neural_2018,
	title = {Neural Networks and Deep Learning},
	url = {http://neuralnetworksanddeeplearning.com/},
	publisher = {Determination Press},
	author = {Nielsen, Michael A.},
	year = {2018},
	keywords = {ba-2018-hahnrico}
}

@article{baxt_use_1991,
	title = {Use of an artificial neural network for the diagnosis of myocardial infarction},
	volume = {115},
	pages = {843--848},
	number = {11},
	journaltitle = {Annals of internal medicine},
	author = {Baxt, William G},
	year = {1991}
}

@book{gershenson_artificial_2003,
	title = {Artificial Neural Networks for Beginners},
	url = {https://login.ezproxy.napier.ac.uk/login?qurl=https%3A%2F%2Fsearch.proquest.com%2Fdocview%2F2091242675%3Faccountid%3D16607},
	author = {Gershenson, Carlos},
	year = {2003},
	keywords = {Artificial neural networks, Neural networks, Algorithms, Artificial Intelligence, Back propagation, Business And Economics–Banking And Finance, Differential calculus, Dummies, Mathematical analysis, Neural and Evolutionary Computation, Vectors (mathematics)}
}

@online{wolfe_understanding_2018,
	title = {Understanding Compositional Pattern Producing Networks},
	url = {https://towardsdatascience.com/understanding-compositional-pattern-producing-networks-810f6bef1b88},
	abstract = {A comprehensive explanation of the theory behind {CPPNS}},
	titleaddon = {Medium},
	author = {Wolfe, Cameron},
	urlyear = {2019-11-10},
	year = {2018},
	langid = {english},
	file = {Snapshot:C\:\\Users\\Andrei\\Zotero\\storage\\8U8XXISF\\understanding-compositional-pattern-producing-networks-810f6bef1b88.html:text/html}
}

@article{stanley_compositional_2007,
	title = {Compositional pattern producing networks: A novel abstraction of development},
	volume = {8},
	issn = {1573-7632},
	url = {https://doi.org/10.1007/s10710-007-9028-8},
	doi = {10.1007/s10710-007-9028-8},
	pages = {131--162},
	number = {2},
	journaltitle = {Genetic Programming and Evolvable Machines},
	author = {Stanley, Kenneth O.},
	year = {2007}
}

@article{stanley_evolving_2002,
	title = {Evolving neural networks through augmenting topologies},
	volume = {10},
	pages = {99--127},
	number = {2},
	journaltitle = {Evolutionary computation},
	author = {Stanley, Kenneth O and Miikkulainen, Risto},
	year = {2002}
}

@article{ben_krose_introduction_1993,
	title = {An introduction to neural networks},
	author = {{Ben Kröse} and {Patrick van der Smagt}},
	year = {1993}
}

@article{aydinalp-koksal_comparison_2008,
	title = {Comparison of neural network, conditional demand analysis, and engineering approaches for modeling end-use energy consumption in the residential sector},
	volume = {85},
	issn = {0306-2619},
	url = {http://www.sciencedirect.com/science/article/pii/S030626190600136X},
	doi = {https://doi.org/10.1016/j.apenergy.2006.09.012},
	pages = {271 -- 296},
	number = {4},
	journaltitle = {Applied Energy},
	author = {Aydinalp-Koksal, Merih and Ugursal, V. Ismet},
	year = {2008},
	keywords = {Conditional demand analysis, Neural networks modeling, Residential energy consumption modeling}
}

@online{heidenreich_neat:_2019,
	title = {{NEAT}: An Awesome Approach to {NeuroEvolution}},
	url = {http://hunterheidenreich.com/blog/neuroevolution-of-augmenting-topologies/},
	shorttitle = {{NEAT}},
	abstract = {{NeuroEvolution} can optimize and evolve neural network structure, and the {NEAT} algorithm was one of the first to show it as a viable approach!},
	author = {Heidenreich, Hunter},
	urlyear = {2019-11-11},
	year = {2019},
	langid = {english},
	file = {Snapshot:C\:\\Users\\Andrei\\Zotero\\storage\\WG4VZL2A\\neuroevolution-of-augmenting-topologies.html:text/html}
}

@online{noauthor_picbreeder_noyear,
	title = {Picbreeder},
	rights = {University of Central Florida},
	url = {http://picbreeder.com/},
	urlyear = {2019-11-15},
	file = {Picbreeder:C\:\\Users\\Andrei\\Zotero\\storage\\Z4XA5VSR\\picbreeder.com.html:text/html}
}

@book{richard_s._sutton_reinforcement_1998,
	location = {Cambridge, Massachusetts, Piscataqay, New Jersey]},
	title = {Reinforcement learning: an introduction},
	isbn = {9786612096785},
	series = {Adaptive computation and machine learning series},
	shorttitle = {Reinforcement learning},
	abstract = {Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability.The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part {II} provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part {III} presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.},
	pagetotal = {xviii+322},
	publisher = {{MIT} Press, {IEEE} Xplore},
	author = {{Richard S. Sutton} and {Andrew G. Barto}},
	year = {1998},
	keywords = {Reinforcement learning.; Machine learning.; Electronic books}
}